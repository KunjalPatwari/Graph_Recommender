{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5365c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, RGCNConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad880492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolutionUnit(nn.Module):\n",
    "    \"\"\"\n",
    "    RE-GCN Evolution Unit that combines GCN and GRU with pooling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim, num_relations=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Relation-aware GCN (or regular GCN if num_relations=1)\n",
    "        if num_relations > 1:\n",
    "            self.gcn = RGCNConv(hidden_dim, hidden_dim, num_relations)\n",
    "        else:\n",
    "            self.gcn = GCNConv(hidden_dim, hidden_dim)\n",
    "            \n",
    "        # GRU for temporal evolution\n",
    "        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Pooling mechanism for historical states\n",
    "        self.pooling_weights = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        # Static graph constraint (attention mechanism)\n",
    "        self.static_attention = nn.MultiheadAttention(hidden_dim, num_heads=4, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Time gate for controlling temporal influence\n",
    "        self.time_gate = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Store historical states for pooling\n",
    "        self.historical_states = []\n",
    "        self.max_history = 10  # Limit memory usage\n",
    "        \n",
    "    def apply_pooling(self, current_state):\n",
    "        \"\"\"\n",
    "        Apply pooling operation to aggregate historical information\n",
    "        \"\"\"\n",
    "        if len(self.historical_states) == 0:\n",
    "            return current_state\n",
    "            \n",
    "        # Stack historical states: [history_len, num_nodes, hidden_dim]\n",
    "        historical_tensor = torch.stack(self.historical_states, dim=0)\n",
    "        \n",
    "        # Compute attention weights for pooling\n",
    "        pooling_scores = self.pooling_weights(historical_tensor)  # [history_len, num_nodes, 1]\n",
    "        pooling_weights = F.softmax(pooling_scores, dim=0)  # Normalize over history\n",
    "        \n",
    "        # Weighted sum of historical states\n",
    "        pooled_history = torch.sum(pooling_weights * historical_tensor, dim=0)  # [num_nodes, hidden_dim]\n",
    "        \n",
    "        return pooled_history\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_type=None, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Forward pass through evolution unit\n",
    "        \n",
    "        Args:\n",
    "            x: Node features [num_nodes, hidden_dim]\n",
    "            edge_index: Edge indices [2, num_edges]\n",
    "            edge_type: Edge types [num_edges] (optional)\n",
    "            hidden_state: Previous hidden state [num_nodes, hidden_dim]\n",
    "        \"\"\"\n",
    "        # 1. Graph Convolution\n",
    "        if edge_type is not None and hasattr(self.gcn, 'num_relations'):\n",
    "            h_gcn = self.gcn(x, edge_index, edge_type)\n",
    "        else:\n",
    "            h_gcn = self.gcn(x, edge_index)\n",
    "            \n",
    "        h_gcn = F.relu(h_gcn)\n",
    "        h_gcn = self.dropout(h_gcn)\n",
    "        \n",
    "        # 2. Apply pooling with historical information\n",
    "        h_pooled = self.apply_pooling(h_gcn)\n",
    "        \n",
    "        # 3. Static graph constraint via self-attention\n",
    "        h_static, _ = self.static_attention(h_pooled.unsqueeze(0), h_pooled.unsqueeze(0), h_pooled.unsqueeze(0))\n",
    "        h_static = h_static.squeeze(0)\n",
    "        \n",
    "        # 4. Temporal evolution with GRU\n",
    "        if hidden_state is not None:\n",
    "            # Time gate to control influence of previous state\n",
    "            gate_input = torch.cat([h_static, hidden_state], dim=1)\n",
    "            time_weight = self.time_gate(gate_input)\n",
    "            gated_hidden = time_weight * hidden_state\n",
    "            \n",
    "            h_new = self.gru(h_static, gated_hidden)\n",
    "        else:\n",
    "            h_new = self.gru(h_static, torch.zeros_like(h_static))\n",
    "        \n",
    "        # 5. Update historical states for pooling\n",
    "        self.historical_states.append(h_new.detach().clone())\n",
    "        if len(self.historical_states) > self.max_history:\n",
    "            self.historical_states.pop(0)  # Remove oldest state\n",
    "            \n",
    "        return h_new\n",
    "\n",
    "class TemporalGCNRecommender(nn.Module):\n",
    "    \"\"\"\n",
    "    RE-GCN style temporal recommender for product recommendations\n",
    "    \n",
    "    This model:\n",
    "    1. Uses Evolution Units that combine GCN + GRU + Pooling\n",
    "    2. Predicts user-product interactions and their weights (quantities)\n",
    "    3. Handles bipartite user-product graphs with temporal evolution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_products, node_features_dim, hidden_dim=64, num_layers=2, dropout=0.1, num_relations=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_products = num_products\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Node embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, hidden_dim)\n",
    "        self.product_embedding = nn.Embedding(num_products, hidden_dim)\n",
    "        \n",
    "        # Feature projection\n",
    "        self.feature_proj = nn.Linear(node_features_dim, hidden_dim)\n",
    "        \n",
    "        # Evolution Units (RE-GCN style)\n",
    "        self.evolution_units = nn.ModuleList([\n",
    "            EvolutionUnit(hidden_dim, num_relations, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Score functions for entity and relation prediction\n",
    "        self.entity_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relation_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)  # Predicts quantity/weight\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize hidden states for each evolution unit\n",
    "        self.reset_hidden_states()\n",
    "    \n",
    "    def reset_hidden_states(self):\n",
    "        \"\"\"Reset hidden states and historical information for new sequence\"\"\"\n",
    "        self.hidden_states = [None] * self.num_layers\n",
    "        for unit in self.evolution_units:\n",
    "            unit.historical_states = []\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None, user_indices=None, product_indices=None, edge_type=None):\n",
    "        \"\"\"\n",
    "        Forward pass for temporal link prediction\n",
    "        \n",
    "        Args:\n",
    "            x: Node features [num_nodes, feature_dim]\n",
    "            edge_index: Edge indices [2, num_edges]\n",
    "            edge_attr: Edge attributes [num_edges, 2] (quantity, timestamp)\n",
    "            user_indices: User node indices for prediction\n",
    "            product_indices: Product node indices for prediction\n",
    "            edge_type: Edge types [num_edges] (optional)\n",
    "        \"\"\"\n",
    "        # Project features to hidden dimension\n",
    "        h = self.feature_proj(x)\n",
    "        \n",
    "        # Add positional embeddings\n",
    "        user_emb = self.user_embedding(torch.arange(self.num_users, device=x.device))\n",
    "        product_emb = self.product_embedding(torch.arange(self.num_products, device=x.device))\n",
    "        \n",
    "        h[:self.num_users] += user_emb\n",
    "        h[self.num_users:] += product_emb\n",
    "        \n",
    "        # Pass through Evolution Units\n",
    "        for layer_idx, evolution_unit in enumerate(self.evolution_units):\n",
    "            h = evolution_unit(h, edge_index, edge_type, self.hidden_states[layer_idx])\n",
    "            self.hidden_states[layer_idx] = h.detach()\n",
    "        \n",
    "        # If no specific indices provided, return node embeddings\n",
    "        if user_indices is None or product_indices is None:\n",
    "            return h\n",
    "        \n",
    "        # Extract user and product embeddings for prediction\n",
    "        user_embeddings = h[user_indices]\n",
    "        product_embeddings = h[product_indices]\n",
    "        \n",
    "        # Concatenate user and product embeddings\n",
    "        edge_embeddings = torch.cat([user_embeddings, product_embeddings], dim=1)\n",
    "        \n",
    "        # Predict using score functions (following RE-GCN paper)\n",
    "        entity_scores = self.entity_predictor(edge_embeddings).squeeze()  # Link existence\n",
    "        relation_scores = self.relation_predictor(edge_embeddings).squeeze()  # Edge weights\n",
    "        \n",
    "        return entity_scores, relation_scores, h\n",
    "\n",
    "class TemporalRecommenderTrainer:\n",
    "    \"\"\"Training and evaluation pipeline for temporal recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tkg_data, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.tkg_data = tkg_data\n",
    "        \n",
    "        # Prepare temporal snapshots\n",
    "        self.temporal_snapshots = self.create_temporal_snapshots()\n",
    "        \n",
    "    def create_temporal_snapshots(self, time_window_hours=24):\n",
    "        \"\"\"\n",
    "        Create temporal snapshots from TKG data\n",
    "        \"\"\"\n",
    "        quadruples = self.tkg_data['quadruples']\n",
    "        \n",
    "        # Group quadruples by time windows\n",
    "        snapshots = {}\n",
    "        min_time = min(q[3] for q in quadruples)\n",
    "        \n",
    "        for user_id, quantity, product_id, timestamp in quadruples:\n",
    "            # Calculate time window\n",
    "            hours_since_start = (timestamp - min_time).total_seconds() / 3600\n",
    "            window_id = int(hours_since_start // time_window_hours)\n",
    "            \n",
    "            if window_id not in snapshots:\n",
    "                snapshots[window_id] = []\n",
    "            \n",
    "            snapshots[window_id].append((user_id, quantity, product_id, timestamp))\n",
    "        \n",
    "        # Convert to sorted list\n",
    "        sorted_snapshots = [snapshots[i] for i in sorted(snapshots.keys())]\n",
    "        \n",
    "        print(f\"Created {len(sorted_snapshots)} temporal snapshots\")\n",
    "        return sorted_snapshots\n",
    "    \n",
    "    def prepare_snapshot_data(self, snapshot_edges):\n",
    "        \"\"\"Prepare PyG data for a single snapshot\"\"\"\n",
    "        \n",
    "        # Extract edges and attributes\n",
    "        edge_list = []\n",
    "        edge_weights = []\n",
    "        \n",
    "        for user_id, quantity, product_id, timestamp in snapshot_edges:\n",
    "            edge_list.append([user_id, product_id])\n",
    "            edge_weights.append(quantity)\n",
    "        \n",
    "        if len(edge_list) == 0:\n",
    "            return None, None, None\n",
    "        \n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_weights, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        return edge_index, edge_attr, edge_list\n",
    "    \n",
    "    def create_negative_samples(self, positive_edges, num_negative=None):\n",
    "        \"\"\"Create negative samples for link prediction\"\"\"\n",
    "        \n",
    "        if num_negative is None:\n",
    "            num_negative = len(positive_edges)\n",
    "        \n",
    "        negative_edges = []\n",
    "        user_ids = set(edge[0] for edge in positive_edges)\n",
    "        product_ids = set(edge[1] for edge in positive_edges)\n",
    "        positive_set = set((edge[0], edge[1]) for edge in positive_edges)\n",
    "        \n",
    "        while len(negative_edges) < num_negative:\n",
    "            user_id = random.choice(list(user_ids))\n",
    "            product_id = random.choice(list(product_ids))\n",
    "            \n",
    "            if (user_id, product_id) not in positive_set:\n",
    "                negative_edges.append([user_id, product_id])\n",
    "                positive_set.add((user_id, product_id))  # Avoid duplicates\n",
    "        \n",
    "        return negative_edges\n",
    "    \n",
    "    def train_epoch(self, optimizer, train_snapshots):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Reset hidden states for new epoch\n",
    "        self.model.reset_hidden_states()\n",
    "        \n",
    "        for snapshot_idx, snapshot_edges in enumerate(tqdm(train_snapshots, desc=\"Training\")):\n",
    "            \n",
    "            edge_index, edge_attr, edge_list = self.prepare_snapshot_data(snapshot_edges)\n",
    "            \n",
    "            if edge_index is None:\n",
    "                continue\n",
    "            \n",
    "            # Move to device\n",
    "            x = self.tkg_data['x'].to(self.device)\n",
    "            edge_index = edge_index.to(self.device)\n",
    "            edge_attr = edge_attr.to(self.device)\n",
    "            \n",
    "            # Create positive and negative samples\n",
    "            positive_edges = edge_list\n",
    "            negative_edges = self.create_negative_samples(positive_edges)\n",
    "            \n",
    "            # Prepare training data\n",
    "            all_edges = positive_edges + negative_edges\n",
    "            labels = torch.cat([\n",
    "                torch.ones(len(positive_edges)),\n",
    "                torch.zeros(len(negative_edges))\n",
    "            ]).to(self.device)\n",
    "            \n",
    "            # Extract edge weights (only for positive edges)\n",
    "            true_weights = torch.tensor([edge[1] for edge in snapshot_edges], dtype=torch.float).to(self.device)\n",
    "            # Normalize weights to [0, 1] range\n",
    "            if len(true_weights) > 0:\n",
    "                true_weights = (true_weights - true_weights.min()) / (true_weights.max() - true_weights.min() + 1e-8)\n",
    "            \n",
    "            # Get user and product indices\n",
    "            user_indices = torch.tensor([edge[0] for edge in all_edges], dtype=torch.long).to(self.device)\n",
    "            product_indices = torch.tensor([edge[1] for edge in all_edges], dtype=torch.long).to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            entity_scores, relation_scores, _ = self.model(x, edge_index, edge_attr, user_indices, product_indices)\n",
    "            \n",
    "            # Entity prediction loss (link existence)\n",
    "            entity_loss = F.binary_cross_entropy(entity_scores, labels)\n",
    "            \n",
    "            # Relation prediction loss (edge weights, only for positive edges)\n",
    "            if len(true_weights) > 0:\n",
    "                relation_loss = F.mse_loss(relation_scores[:len(positive_edges)], true_weights)\n",
    "            else:\n",
    "                relation_loss = torch.tensor(0.0, device=self.device)\n",
    "            \n",
    "            # Combined loss (following RE-GCN formulation)\n",
    "            total_loss_batch = entity_loss + 0.5 * relation_loss\n",
    "            \n",
    "            total_loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += total_loss_batch.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        return total_loss / max(num_batches, 1)\n",
    "    \n",
    "    def evaluate(self, test_snapshots):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        all_entity_preds = []\n",
    "        all_entity_labels = []\n",
    "        all_relation_preds = []\n",
    "        all_relation_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Reset hidden states\n",
    "            self.model.reset_hidden_states()\n",
    "            \n",
    "            for snapshot_edges in tqdm(test_snapshots, desc=\"Evaluating\"):\n",
    "                \n",
    "                edge_index, edge_attr, edge_list = self.prepare_snapshot_data(snapshot_edges)\n",
    "                \n",
    "                if edge_index is None:\n",
    "                    continue\n",
    "                \n",
    "                # Move to device\n",
    "                x = self.tkg_data['x'].to(self.device)\n",
    "                edge_index = edge_index.to(self.device)\n",
    "                edge_attr = edge_attr.to(self.device)\n",
    "                \n",
    "                # Create test samples\n",
    "                positive_edges = edge_list\n",
    "                negative_edges = self.create_negative_samples(positive_edges)\n",
    "                \n",
    "                all_edges = positive_edges + negative_edges\n",
    "                labels = torch.cat([\n",
    "                    torch.ones(len(positive_edges)),\n",
    "                    torch.zeros(len(negative_edges))\n",
    "                ])\n",
    "                \n",
    "                # True weights\n",
    "                true_weights = torch.tensor([q for _, q, _, _ in snapshot_edges], dtype=torch.float)\n",
    "                if len(true_weights) > 0:\n",
    "                    true_weights = (true_weights - true_weights.min()) / (true_weights.max() - true_weights.min() + 1e-8)\n",
    "                \n",
    "                # Get indices\n",
    "                user_indices = torch.tensor([edge[0] for edge in all_edges], dtype=torch.long).to(self.device)\n",
    "                product_indices = torch.tensor([edge[1] for edge in all_edges], dtype=torch.long).to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                entity_scores, relation_scores, _ = self.model(x, edge_index, edge_attr, user_indices, product_indices)\n",
    "                \n",
    "                # Collect predictions\n",
    "                all_entity_preds.extend(entity_scores.cpu().numpy())\n",
    "                all_entity_labels.extend(labels.numpy())\n",
    "                \n",
    "                if len(true_weights) > 0:\n",
    "                    all_relation_preds.extend(relation_scores[:len(positive_edges)].cpu().numpy())\n",
    "                    all_relation_labels.extend(true_weights.numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if len(all_entity_preds) > 0:\n",
    "            entity_auc = roc_auc_score(all_entity_labels, all_entity_preds)\n",
    "            entity_ap = average_precision_score(all_entity_labels, all_entity_preds)\n",
    "        else:\n",
    "            entity_auc = entity_ap = 0.0\n",
    "        \n",
    "        if len(all_relation_preds) > 0:\n",
    "            relation_mse = np.mean((np.array(all_relation_preds) - np.array(all_relation_labels)) ** 2)\n",
    "        else:\n",
    "            relation_mse = 0.0\n",
    "        \n",
    "        return {\n",
    "            'entity_auc': entity_auc,\n",
    "            'entity_ap': entity_ap,\n",
    "            'relation_mse': relation_mse\n",
    "        }\n",
    "    \n",
    "    def train(self, num_epochs=50, lr=0.01, train_ratio=0.8):\n",
    "        \"\"\"Full training pipeline\"\"\"\n",
    "        \n",
    "        # Split temporal snapshots\n",
    "        split_idx = int(len(self.temporal_snapshots) * train_ratio)\n",
    "        train_snapshots = self.temporal_snapshots[:split_idx]\n",
    "        test_snapshots = self.temporal_snapshots[split_idx:]\n",
    "        \n",
    "        print(f\"Training on {len(train_snapshots)} snapshots, testing on {len(test_snapshots)} snapshots\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "        \n",
    "        best_auc = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch(optimizer, train_snapshots)\n",
    "            \n",
    "            # Evaluate\n",
    "            if epoch % 5 == 0:\n",
    "                metrics = self.evaluate(test_snapshots)\n",
    "                \n",
    "                print(f\"Epoch {epoch:3d}: Loss={train_loss:.4f}, \"\n",
    "                      f\"Entity AUC={metrics['entity_auc']:.4f}, \"\n",
    "                      f\"Entity AP={metrics['entity_ap']:.4f}, \"\n",
    "                      f\"Relation MSE={metrics['relation_mse']:.4f}\")\n",
    "                \n",
    "                if metrics['entity_auc'] > best_auc:\n",
    "                    best_auc = metrics['entity_auc']\n",
    "                    torch.save(self.model.state_dict(), 'best_temporal_recommender.pt')\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        # Load best model\n",
    "        self.model.load_state_dict(torch.load('best_temporal_recommender.pt'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        final_metrics = self.evaluate(test_snapshots)\n",
    "        print(f\"\\nFinal Results:\")\n",
    "        print(f\"Entity AUC: {final_metrics['entity_auc']:.4f}\")\n",
    "        print(f\"Entity AP: {final_metrics['entity_ap']:.4f}\")\n",
    "        print(f\"Relation MSE: {final_metrics['relation_mse']:.4f}\")\n",
    "        \n",
    "        return final_metrics\n",
    "    \n",
    "    def recommend_products(self, user_id, top_k=10, exclude_existing=True):\n",
    "        \"\"\"\n",
    "        Generate product recommendations for a user\n",
    "        \n",
    "        Args:\n",
    "            user_id: Target user ID\n",
    "            top_k: Number of recommendations\n",
    "            exclude_existing: Whether to exclude products user already bought\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = self.tkg_data['x'].to(self.device)\n",
    "            \n",
    "            # Get all products\n",
    "            all_product_ids = list(range(self.tkg_data['num_users'], \n",
    "                                       self.tkg_data['num_users'] + self.tkg_data['num_products']))\n",
    "            \n",
    "            # Exclude existing products if requested\n",
    "            if exclude_existing:\n",
    "                existing_products = set()\n",
    "                for quad in self.tkg_data['quadruples']:\n",
    "                    if quad[0] == user_id:  # user_id matches\n",
    "                        existing_products.add(quad[2])  # product_id\n",
    "                \n",
    "                candidate_products = [pid for pid in all_product_ids if pid not in existing_products]\n",
    "            else:\n",
    "                candidate_products = all_product_ids\n",
    "            \n",
    "            if len(candidate_products) == 0:\n",
    "                return []\n",
    "            \n",
    "            # Create dummy edge index (we need this for the forward pass)\n",
    "            dummy_edges = [[user_id, pid] for pid in candidate_products[:min(100, len(candidate_products))]]\n",
    "            edge_index = torch.tensor(dummy_edges, dtype=torch.long).t().contiguous().to(self.device)\n",
    "            edge_attr = torch.zeros((len(dummy_edges), 1), dtype=torch.float).to(self.device)\n",
    "            \n",
    "            # Prepare indices for prediction\n",
    "            user_indices = torch.tensor([user_id] * len(dummy_edges), dtype=torch.long).to(self.device)\n",
    "            product_indices = torch.tensor([edge[1] for edge in dummy_edges], dtype=torch.long).to(self.device)\n",
    "            \n",
    "            # Get predictions\n",
    "            entity_scores, relation_scores, _ = self.model(x, edge_index, edge_attr, user_indices, product_indices)\n",
    "            \n",
    "            # Combine scores (entity probability * predicted relation strength)\n",
    "            combined_scores = entity_scores * torch.abs(relation_scores)  # Use absolute value for relation scores\n",
    "            \n",
    "            # Get top-k recommendations\n",
    "            top_indices = torch.argsort(combined_scores, descending=True)[:top_k]\n",
    "            \n",
    "            recommendations = []\n",
    "            for idx in top_indices:\n",
    "                product_id = dummy_edges[idx][1]\n",
    "                score = combined_scores[idx].item()\n",
    "                entity_prob = entity_scores[idx].item()\n",
    "                relation_strength = relation_scores[idx].item()\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'product_id': product_id,\n",
    "                    'product_name': self.tkg_data.get('id_to_product', {}).get(product_id, f'Product_{product_id}'),\n",
    "                    'score': score,\n",
    "                    'entity_probability': entity_prob,\n",
    "                    'relation_strength': relation_strength\n",
    "                })\n",
    "            \n",
    "            return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8f9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize model\\nmodel = TemporalGCNRecommender(\\n    num_users=tkg_data[\\'num_users\\'],\\n    num_products=tkg_data[\\'num_products\\'],\\n    node_features_dim=tkg_data[\\'x\\'].shape[1],\\n    hidden_dim=64\\n)\\n\\n# Initialize trainer\\ntrainer = TemporalRecommenderTrainer(model, tkg_data, device=\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n\\n# Train the model\\nresults = trainer.train(num_epochs=30, lr=0.01)\\n\\n# Get recommendations for user\\nuser_id = 0  # First user\\nrecommendations = trainer.recommend_products(user_id, top_k=10)\\n\\nprint(f\"Top recommendations for user {user_id}:\")\\nfor i, rec in enumerate(recommendations, 1):\\n    print(f\"{i}. {rec[\\'product_name\\']}\")\\n    print(f\"   Score: {rec[\\'score\\']:.3f}, Link Prob: {rec[\\'link_probability\\']:.3f}, Pred Qty: {rec[\\'predicted_quantity\\']:.2f}\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your TKG data\n",
    "tkg_data = torch.load('graph/my_retail_tkg_pyg.pt', weights_only=False)\n",
    "\"\"\"\n",
    "# Initialize model\n",
    "model = TemporalGCNRecommender(\n",
    "    num_users=tkg_data['num_users'],\n",
    "    num_products=tkg_data['num_products'],\n",
    "    node_features_dim=tkg_data['x'].shape[1],\n",
    "    hidden_dim=64\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = TemporalRecommenderTrainer(model, tkg_data, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train the model\n",
    "results = trainer.train(num_epochs=30, lr=0.01)\n",
    "\n",
    "# Get recommendations for user\n",
    "user_id = 0  # First user\n",
    "recommendations = trainer.recommend_products(user_id, top_k=10)\n",
    "\n",
    "print(f\"Top recommendations for user {user_id}:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec['product_name']}\")\n",
    "    print(f\"   Score: {rec['score']:.3f}, Link Prob: {rec['link_probability']:.3f}, Pred Qty: {rec['predicted_quantity']:.2f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21565ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 305 temporal snapshots\n",
      "Training on 244 snapshots, testing on 61 snapshots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 244/244 [35:09<00:00,  8.64s/it]\n",
      "Evaluating: 100%|██████████| 61/61 [01:39<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: Loss=0.7111, Entity AUC=0.5000, Entity AP=0.4997, Relation MSE=0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|████▉     | 121/244 [15:44<16:00,  7.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m trainer = TemporalRecommenderTrainer(model, tkg_data, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Get recommendations for user\u001b[39;00m\n\u001b[32m     16\u001b[39m user_id = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# First user\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 436\u001b[39m, in \u001b[36mTemporalRecommenderTrainer.train\u001b[39m\u001b[34m(self, num_epochs, lr, train_ratio)\u001b[39m\n\u001b[32m    432\u001b[39m best_auc = \u001b[32m0\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m    434\u001b[39m \n\u001b[32m    435\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_snapshots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 324\u001b[39m, in \u001b[36mTemporalRecommenderTrainer.train_epoch\u001b[39m\u001b[34m(self, optimizer, train_snapshots)\u001b[39m\n\u001b[32m    321\u001b[39m optimizer.zero_grad()\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m entity_scores, relation_scores, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Entity prediction loss (link existence)\u001b[39;00m\n\u001b[32m    327\u001b[39m entity_loss = F.binary_cross_entropy(entity_scores, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 182\u001b[39m, in \u001b[36mTemporalGCNRecommender.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, user_indices, product_indices, edge_type)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# Pass through Evolution Units\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, evolution_unit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.evolution_units):\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     h = \u001b[43mevolution_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mself\u001b[39m.hidden_states[layer_idx] = h.detach()\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# If no specific indices provided, return node embeddings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mEvolutionUnit.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_type, hidden_state)\u001b[39m\n\u001b[32m     77\u001b[39m h_pooled = \u001b[38;5;28mself\u001b[39m.apply_pooling(h_gcn)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# 3. Static graph constraint via self-attention\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m h_static, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatic_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_pooled\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pooled\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pooled\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m h_static = h_static.squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# 4. Temporal evolution with GRU\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:6376\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6374\u001b[39m attn_output_weights = softmax(attn_output_weights, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m   6375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dropout_p > \u001b[32m0.0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6376\u001b[39m     attn_output_weights = \u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6378\u001b[39m attn_output = torch.bmm(attn_output_weights, v)\n\u001b[32m   6380\u001b[39m attn_output = (\n\u001b[32m   6381\u001b[39m     attn_output.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).contiguous().view(tgt_len * bsz, embed_dim)\n\u001b[32m   6382\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNJAL PATWARI\\Yucca_Personal\\Graph_Recommender\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = TemporalGCNRecommender(\n",
    "    num_users=tkg_data['num_users'],\n",
    "    num_products=tkg_data['num_products'],\n",
    "    node_features_dim=tkg_data['x'].shape[1],\n",
    "    hidden_dim=64\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = TemporalRecommenderTrainer(model, tkg_data, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train the model\n",
    "results = trainer.train(num_epochs=30, lr=0.01)\n",
    "\n",
    "# Get recommendations for user\n",
    "user_id = 0  # First user\n",
    "recommendations = trainer.recommend_products(user_id, top_k=10)\n",
    "\n",
    "print(f\"Top recommendations for user {user_id}:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec['product_name']}\")\n",
    "    print(f\"   Score: {rec['score']:.3f}, Link Prob: {rec['link_probability']:.3f}, Pred Qty: {rec['predicted_quantity']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8009c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model - takes seconds\n",
    "model = TemporalGCNRecommender(\n",
    "    num_users=tkg_data['num_users'],\n",
    "    num_products=tkg_data['num_products'],\n",
    "    node_features_dim=tkg_data['x'].shape[1],\n",
    "    hidden_dim=64\n",
    ")\n",
    "model.load_state_dict(torch.load('best_temporal_recommender.pt'))\n",
    "\n",
    "# Get recommendations instantly (milliseconds)\n",
    "recommendations = trainer.recommend_products(user_id=1002, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
